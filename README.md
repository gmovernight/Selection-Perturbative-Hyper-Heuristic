# Selection Perturbative Hyper‚ÄëHeuristic (SPHH)

This is my reproducible Python implementation of a **single‚Äëpoint Selection Perturbative Hyper‚ÄëHeuristic (SPHH)** with a benchmark suite (f1‚Äìf24) from the Research Paper: **"A modified particle swarm optimization algorithm based on velocity updating mechanism by Chunfeng Wang and Wenxin Song"** and a full experiment pipeline: run all problems across multiple seeds, aggregate results, export publication‚Äëready tables, and plot **log‚Äëscaled optimality‚Äëgap** convergence curves.

> Python 3.10+ is recommended. Dependencies: **numpy**, **matplotlib**.

---

## ‚ú® What‚Äôs inside

- **SPHH optimizer & benchmark registry** ‚Äî `single_point_sphh.py` defines:
  - Six low‚Äëlevel perturbative heuristics (LLHs): `gaussian_full`, `gaussian_kdims`, `cauchy_full`, `random_reset_coord`, `opposition_blend`, `pull_to_best`.
  - Selection modes: **UCB1** bandit (`selection_mode="ucb"`) and **uniform random** (`"random"`).
  - Acceptance modes: **Simulated Annealing** (`acceptance_mode="sa"`) and **Greedy** (`"greedy"`).
  - Step‚Äësize self‚Äëadaptation using the **1/5 success rule** (update every 50 evals).
  - A small `OBJECTIVES` registry mapping names (e.g., `f3_D10`) to `(func, lo, hi, D)`.

- **Experiment config** ‚Äî `exp_config.py` centralizes **seeds** and **per‚Äëdimension evaluation budgets**, plus the `results/` directory path.

- **Batch runner** ‚Äî `run_suite.py` iterates over all objective keys √ó seeds and writes one row per run to `results/seeds_all.csv`.

- **Aggregator** ‚Äî `aggregate_suite.py` groups by function key and writes `results/summary_all.csv` with mean/std/best and runtime stats.

- **Table builders** ‚Äî `make_tables.py` ‚Üí `results/tables.md` (Markdown) and `results/tables.tex` (LaTeX).

- **Params snapshot** ‚Äî `make_params_table.py` records your final settings to `results/params.md` / `results/params.tex` (selection/acceptance, budgets, etc.).

- **Convergence plots** ‚Äî `plot_convergence.py` re‚Äëruns selected base functions (`BASE_FUNCTIONS = ["f24"]` by default) and writes **PNG plots** to `results/plots/` and median **CSV traces** to `results/traces/` using **|f ‚àí f\*|** on a log y‚Äëaxis.

---

## üöÄ Quickstart (full pipeline)

```bash
# 1) (optional) create and activate a virtualenv
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# 2) install dependencies
pip install numpy matplotlib

# 3) run all objectives across all seeds; write per‚Äërun CSV
python run_suite.py

# 4) aggregate per‚Äërun CSV into a per‚Äëfunction summary
python aggregate_suite.py

# 5) build Markdown/LaTeX tables from the summary
python make_tables.py

# 6) record the experiment parameters you used (Markdown + LaTeX)
python make_params_table.py

# 7) (optional) plot convergence curves and write CSV traces
python plot_convergence.py
```

All outputs are written to the **`results/`** folder (created automatically). See the tree below.

---

## ‚öôÔ∏è Setup

- **Python**: 3.10+ recommended  
- **Packages**: `numpy`, `matplotlib`  
- **Working dir**: run all commands from the repo root

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
pip install numpy matplotlib
```

---

## üß™ SPHH in a nutshell

- **Single‚Äëpoint search**: maintain one incumbent `x` within bounds `[‚Ñì, u]^D`.
- **Operator pool (LLHs)**: propose `x'` via one of six perturbation heuristics, then clamp to bounds.
- **Heuristic selection**: choose the next LLH using **UCB1** (or **random** for ablations).
- **Move acceptance**: accept with **SA** (or **greedy** for ablations).
- **Self‚Äëadaptation**: per‚Äëdimension step sizes shrink/expand via the **1/5 success rule**.
- **Verbose single run**: run `python single_point_sphh.py` to print iterations for a chosen problem.

Key constructor args (see `single_point_sphh.py`):
```python
SPHH(
  objective, bounds=(lo, hi), dim=D, max_evals=...,
  seed=..., selection_mode="ucb"|"random",
  acceptance_mode="sa"|"greedy", ucb_c=1.5, cooling_frac=0.2,
  init="random", verbose=False, print_every=...
)
```

---

## üì¶ Repository structure & outputs

```
results/
  seeds_all.csv         # one row per (objective key, seed) run
  summary_all.csv       # aggregated stats per function key
  tables.md             # Markdown tables (by base function √ó D)
  tables.tex            # LaTeX tables
  params.md             # experiment parameters (human‚Äëreadable)
  params.tex            # LaTeX version of parameters
  plots/
    conv_gap_<base>.png # log‚Äëscale optimality‚Äëgap plots by D
  traces/
    trace_gap_<key>.csv # median optimality‚Äëgap vs eval index
```

---

## üõ†Ô∏è Customization

### Seeds & budgets
Edit **`exp_config.py`**:
- `SEEDS = list(range(10))` ‚Üí change number/values of seeds.
- `MAX_EVALS_BY_D = {10:..., 30:..., 50:...}` ‚Üí per‚Äëdimension evaluation budgets (fallback to `MAX_EVALS_DEFAULT`).

### Which objectives run
`run_suite.py` runs **every key** in `OBJECTIVES` (e.g., `f3_D10`, `f3_D30`, `f3_D50`, ‚Ä¶). To restrict:
- Temporarily comment out entries in `OBJECTIVES` in `single_point_sphh.py`, **or**
- Add a filter inside `sorted_keys()` in `run_suite.py`.

### SPHH modes & verbosity
- Suite defaults: `selection_mode="ucb"`, `acceptance_mode="sa"`, `verbose=False` (set inside `run_suite.py`).
- For a one‚Äëoff verbose run, execute `python single_point_sphh.py` and adjust `which`, `max_evals`, `verbose`, `print_every` at the bottom.

### Convergence plots
- Edit `BASE_FUNCTIONS` in `plot_convergence.py` to select base functions (e.g., `"f17","f21","f23","f4"`).
- Update `FSTAR_BY_BASE` for any base with **non‚Äëzero** optimum (e.g., `f2`, `f17`) to keep the **optimality‚Äëgap** correct.

---

## üìä Tables & figures

- `make_tables.py` generates compact tables with: `D`, `f_best`, `mean_f_best`, `f_best_std_dev`, `mean run time (s)` for each base function.
- `plot_convergence.py` produces log‚Äëscale optimality‚Äëgap curves by dimension and writes the per‚Äëbase median gap traces as CSV for reproducibility.

---

## üß© Reproducibility notes

- All randomness is seeded via `exp_config.SEEDS` and numpy‚Äôs `default_rng` in `SPHH`.
- Budgets are controlled centrally (`exp_config.budget_for_dim(D)`) so changing one place updates the entire pipeline.
- The aggregator and table builders are pure functions of the CSV outputs ‚Äì delete `results/` and re‚Äërun to regenerate everything.

---




